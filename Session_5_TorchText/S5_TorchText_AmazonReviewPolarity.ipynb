{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S5_TorchText_AmazonReviewPolarity.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/m-shilpa/END3/blob/main/Session_5_TorchText/S5_TorchText_AmazonReviewPolarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKb3KfJgzpun"
      },
      "source": [
        "from torchtext.datasets import AmazonReviewPolarity"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pXFnhhMzx4R",
        "outputId": "285e9607-cb8f-469a-9c72-3786366152a3"
      },
      "source": [
        "help(AmazonReviewPolarity)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function AmazonReviewPolarity in module torchtext.datasets.amazonreviewpolarity:\n",
            "\n",
            "AmazonReviewPolarity(root='.data', split=('train', 'test'))\n",
            "    AmazonReviewPolarity dataset\n",
            "    \n",
            "    Separately returns the train/test split\n",
            "    \n",
            "    Number of lines per split:\n",
            "        train: 3600000\n",
            "    \n",
            "        test: 400000\n",
            "    \n",
            "    \n",
            "    Number of classes\n",
            "        2\n",
            "    \n",
            "    \n",
            "    Args:\n",
            "        root: Directory where the datasets are saved.\n",
            "            Default: .data\n",
            "        split: split or splits to be returned. Can be a string or tuple of strings.\n",
            "            Default: ('train', 'test')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_aDHs5UdKNV",
        "outputId": "ebe52c68-1d87-488e-83aa-0da6aebd832f"
      },
      "source": [
        "test_iter = AmazonReviewPolarity(split='test')\n",
        "\n",
        "negative_test_samples = 0\n",
        "positive_test_samples = 0\n",
        "for index, (label,text) in enumerate(test_iter):\n",
        "    if label == 1:\n",
        "        negative_test_samples +=1\n",
        "    else:\n",
        "        positive_test_samples +=1\n",
        "\n",
        "print('Number of Positive reviews:',positive_test_samples)\n",
        "print('Number of Negative reviews:',negative_test_samples)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Positive reviews: 200000\n",
            "Number of Negative reviews: 200000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeG45M5Pdxpk",
        "outputId": "8c48a41b-1ad4-4861-a619-a4f0d693b7e5"
      },
      "source": [
        "train_iter = AmazonReviewPolarity(split='train')\n",
        "\n",
        "negative_train_samples = 0\n",
        "positive_train_samples = 0\n",
        "for index, (label,text) in enumerate(train_iter):\n",
        "    if label == 1:\n",
        "        negative_train_samples +=1\n",
        "    else:\n",
        "        positive_train_samples +=1\n",
        "\n",
        "print('Number of Positive reviews:',positive_train_samples)\n",
        "print('Number of Negative reviews:',negative_train_samples)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Positive reviews: 1800000\n",
            "Number of Negative reviews: 1800000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3sWLqLmz2tp"
      },
      "source": [
        "train_iter = AmazonReviewPolarity(split='train')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouX7lqki0HbA",
        "outputId": "7d42e87f-355b-467b-823e-f8ec031f381d"
      },
      "source": [
        "type(AmazonReviewPolarity(split='train'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchtext.data.datasets_utils._RawTextIterableDataset"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ev1nEGyC0JVd",
        "outputId": "26779cd0-4518-4e71-91e5-9797063fb596"
      },
      "source": [
        "next(train_iter)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,\n",
              " 'Stuning even for the non-gamer This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrB4PfQA0MQi",
        "outputId": "30d0443e-0059-4c93-e6d7-f011bbca31cb"
      },
      "source": [
        "for (line_number, (label, line)) in enumerate(train_iter):\n",
        "  print(label, line)\n",
        "  if line_number == 19:\n",
        "    break"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 The best soundtrack ever to anything. I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\n",
            "2 Amazing! This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you've played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time's Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer's work (I haven't heard the Xenogears soundtrack, so I can't say for sure), and even if you've never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\n",
            "2 Excellent Soundtrack I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Unstealable Jewel.Overall, this is a excellent soundtrack and should be brought by those that like video game music.Xander Cross\n",
            "2 Remember, Pull Your Jaw Off The Floor After Hearing it If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.\n",
            "2 an absolute masterpiece I am quite sure any of you actually taking the time to read this have played the game at least once, and heard at least a few of the tracks here. And whether you were aware of it or not, Mitsuda's music contributed greatly to the mood of every single minute of the whole game.Composed of 3 CDs and quite a few songs (I haven't an exact count), all of which are heart-rendering and impressively remarkable, this soundtrack is one I assure you you will not forget. It has everything for every listener -- from fast-paced and energetic (Dancing the Tokage or Termina Home), to slower and more haunting (Dragon God), to purely beautifully composed (Time's Scar), to even some fantastic vocals (Radical Dreamers).This is one of the best videogame soundtracks out there, and surely Mitsuda's best ever. ^_^\n",
            "1 Buyer beware This is a self-published book, and if you want to know why--read a few paragraphs! Those 5 star reviews must have been written by Ms. Haddon's family and friends--or perhaps, by herself! I can't imagine anyone reading the whole thing--I spent an evening with the book and a friend and we were in hysterics reading bits and pieces of it to one another. It is most definitely bad enough to be entered into some kind of a \"worst book\" contest. I can't believe Amazon even sells this kind of thing. Maybe I can offer them my 8th grade term paper on \"To Kill a Mockingbird\"--a book I am quite sure Ms. Haddon never heard of. Anyway, unless you are in a mood to send a book to someone as a joke---stay far, far away from this one!\n",
            "2 Glorious story I loved Whisper of the wicked saints. The story was amazing and I was pleasantly surprised at the changes in the book. I am not normaly someone who is into romance novels, but the world was raving about this book and so I bought it. I loved it !! This is a brilliant story because it is so true. This book was so wonderful that I have told all of my friends to read it. It is not a typical romance, it is so much more. Not reading this book is a crime, becuase you are missing out on a heart warming story.\n",
            "2 A FIVE STAR BOOK I just finished reading Whisper of the Wicked saints. I fell in love with the caracters. I expected an average romance read, but instead I found one of my favorite books of all time. Just when I thought I could predict the outcome I was shocked ! The writting was so descriptive that my heart broke when Julia's did and I felt as if I was there with them instead of just a distant reader. If you are a lover of romance novels then this is a must read. Don't let the cover fool you this book is spectacular!\n",
            "2 Whispers of the Wicked Saints This was a easy to read book that made me want to keep reading on and on, not easy to put down.It left me wanting to read the follow on, which I hope is coming soon. I used to read a lot but have gotten away from it. This book made me want to read again. Very enjoyable.\n",
            "1 The Worst! A complete waste of time. Typographical errors, poor grammar, and a totally pathetic plot add up to absolutely nothing. I'm embarrassed for this author and very disappointed I actually paid for this book.\n",
            "2 Great book This was a great book,I just could not put it down,and could not read it fast enough. Boy what a book the twist and turns in this just keeps you guessing and wanting to know what is going to happen next. This book makes you fall in love and can heat you up,it can also make you so angery. this book can make you go throu several of your emotions. This is a quick read romance. It is something that you will want to end your day off with if you read at night.\n",
            "2 Great Read I thought this book was brilliant, but yet realistic. It showed me that to error is human. I loved the fact that this writer showed the loving side of God and not the revengeful side of him. I loved how it twisted and turned and I could not put it down. I also loved The glass castle.\n",
            "1 Oh please I guess you have to be a romance novel lover for this one, and not a very discerning one. All others beware! It is absolute drivel. I figured I was in trouble when a typo is prominently featured on the back cover, but the first page of the book removed all doubt. Wait - maybe I'm missing the point. A quick re-read of the beginning now makes it clear. This has to be an intentional churning of over-heated prose for satiric purposes. Phew, so glad I didn't waste $10.95 after all.\n",
            "1 Awful beyond belief! I feel I have to write to keep others from wasting their money. This book seems to have been written by a 7th grader with poor grammatical skills for her age! As another reviewer points out, there is a misspelling on the cover, and I believe there is at least one per chapter. For example, it was mentioned twice that she had a \"lean\" on her house. I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. Please don't waste your money. I too, believe that the good reviews must have been written by the author's relatives. I will not put much faith in the reviews from now on!\n",
            "1 Don't try to fool us with fake reviews. It's glaringly obvious that all of the glowing reviews have been written by the same person, perhaps the author herself. They all have the same misspellings and poor sentence structure that is featured in the book. Who made Veronica Haddon think she is an author?\n",
            "2 A romantic zen baseball comedy When you hear folks say that they don't make 'em like that anymore, they might be talking about \"BY THE SEA\". This is a very cool story about a young Cuban girl searching for idenity who stumbles into a coastal resort kitchen gig with a zen motorcycle maintenance man, three hysterical Italian chefs and a Latino fireballing right handed pitcher who plays on the team sponsored by the resort's owner. As is often the case she 'finds' herself through honest, often comical but always emotional, interaction with this sizzling roster of players. With the perfect mix of special effects, that salsa sound and flashbacks, BY THE SEA, gets 4 BIG stars from me!\n",
            "2 Fashionable Compression Stockings! After I had a DVT my doctor required me to wear compression stockings. I wore ugly white TED hose and yucky thick brown stockings. Then I found Jobst UltraSheer. They gave me the compression I needed (15-20,) but looked like regular pantyhose. Even though my blood clot has been gone for 4 years, I still buy these to wear as support stockings because they make my legs feel so nice.**Note, I have problems with the rubberized tops rolling down my thigh. I tried the Jobst adhesive, but I hated having my skin pulled all day. I bought an inexpensive garter belt and it works fine and helps keep the stockings from rolling.\n",
            "2 Jobst UltraSheer Thigh High Excellent product. However, they are very difficult to get on for older people. I feel like I've had a full day workout after getting them on. Also, as the day wears on, they begin to roll down from the top and create a very deep ridge in the skin. I have to wear them, so if those two difficulties could be addressed it would be such a help.\n",
            "1 sizes recomended in the size chart are not real sizes are much smaller than what is recomended in the chart. I tried to put it and sheer it!. I guess you should not buy this item in the internet..it is better to go to the store and check it\n",
            "1 mens ultrasheer This model may be ok for sedentary types, but I'm active and get around alot in my job - consistently found these stockings rolled up down by my ankles! Not Good!! Solution: go with the standard compression stocking, 20-30, stock #114622. Excellent support, stays up and gives me what I need. Both pair of these also tore as I struggled to pull them up all the time. Good riddance/bad investment!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7LwnrU-0cMI",
        "outputId": "378cbaa0-d8ff-46d5-861d-e810a9977245"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_iter = AmazonReviewPolarity(split = 'train')\n",
        "\n",
        "help(DataLoader)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on class DataLoader in module torch.utils.data.dataloader:\n",
            "\n",
            "class DataLoader(typing.Generic)\n",
            " |  DataLoader(*args, **kwds)\n",
            " |  \n",
            " |  Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
            " |  the given dataset.\n",
            " |  \n",
            " |  The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
            " |  iterable-style datasets with single- or multi-process loading, customizing\n",
            " |  loading order and optional automatic batching (collation) and memory pinning.\n",
            " |  \n",
            " |  See :py:mod:`torch.utils.data` documentation page for more details.\n",
            " |  \n",
            " |  Args:\n",
            " |      dataset (Dataset): dataset from which to load the data.\n",
            " |      batch_size (int, optional): how many samples per batch to load\n",
            " |          (default: ``1``).\n",
            " |      shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
            " |          at every epoch (default: ``False``).\n",
            " |      sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
            " |          samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
            " |          implemented. If specified, :attr:`shuffle` must not be specified.\n",
            " |      batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
            " |          returns a batch of indices at a time. Mutually exclusive with\n",
            " |          :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
            " |          and :attr:`drop_last`.\n",
            " |      num_workers (int, optional): how many subprocesses to use for data\n",
            " |          loading. ``0`` means that the data will be loaded in the main process.\n",
            " |          (default: ``0``)\n",
            " |      collate_fn (callable, optional): merges a list of samples to form a\n",
            " |          mini-batch of Tensor(s).  Used when using batched loading from a\n",
            " |          map-style dataset.\n",
            " |      pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
            " |          into CUDA pinned memory before returning them.  If your data elements\n",
            " |          are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
            " |          see the example below.\n",
            " |      drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
            " |          if the dataset size is not divisible by the batch size. If ``False`` and\n",
            " |          the size of dataset is not divisible by the batch size, then the last batch\n",
            " |          will be smaller. (default: ``False``)\n",
            " |      timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
            " |          from workers. Should always be non-negative. (default: ``0``)\n",
            " |      worker_init_fn (callable, optional): If not ``None``, this will be called on each\n",
            " |          worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
            " |          input, after seeding and before data loading. (default: ``None``)\n",
            " |      generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
            " |          by RandomSampler to generate random indexes and multiprocessing to generate\n",
            " |          `base_seed` for workers. (default: ``None``)\n",
            " |      prefetch_factor (int, optional, keyword-only arg): Number of samples loaded\n",
            " |          in advance by each worker. ``2`` means there will be a total of\n",
            " |          2 * num_workers samples prefetched across all workers. (default: ``2``)\n",
            " |      persistent_workers (bool, optional): If ``True``, the data loader will not shutdown\n",
            " |          the worker processes after a dataset has been consumed once. This allows to\n",
            " |          maintain the workers `Dataset` instances alive. (default: ``False``)\n",
            " |  \n",
            " |  \n",
            " |  .. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
            " |               cannot be an unpicklable object, e.g., a lambda function. See\n",
            " |               :ref:`multiprocessing-best-practices` on more details related\n",
            " |               to multiprocessing in PyTorch.\n",
            " |  \n",
            " |  .. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
            " |               When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
            " |               it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
            " |               rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
            " |               configurations. This represents the best guess PyTorch can make because PyTorch\n",
            " |               trusts user :attr:`dataset` code in correctly handling multi-process\n",
            " |               loading to avoid duplicate data.\n",
            " |  \n",
            " |               However, if sharding results in multiple workers having incomplete last batches,\n",
            " |               this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
            " |               be broken into multiple ones and (2) more than one batch worth of samples can be\n",
            " |               dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
            " |               cases in general.\n",
            " |  \n",
            " |               See `Dataset Types`_ for more details on these two types of datasets and how\n",
            " |               :class:`~torch.utils.data.IterableDataset` interacts with\n",
            " |               `Multi-process data loading`_.\n",
            " |  \n",
            " |  .. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
            " |               :ref:`data-loading-randomness` notes for random seed related questions.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      DataLoader\n",
            " |      typing.Generic\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, dataset: torch.utils.data.dataset.Dataset[+T_co], batch_size: Union[int, NoneType] = 1, shuffle: bool = False, sampler: Union[torch.utils.data.sampler.Sampler, NoneType] = None, batch_sampler: Union[torch.utils.data.sampler.Sampler[Sequence], NoneType] = None, num_workers: int = 0, collate_fn: Union[Callable[[List[~T]], Any], NoneType] = None, pin_memory: bool = False, drop_last: bool = False, timeout: float = 0, worker_init_fn: Union[Callable[[int], NoneType], NoneType] = None, multiprocessing_context=None, generator=None, *, prefetch_factor: int = 2, persistent_workers: bool = False)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  __iter__(self) -> '_BaseDataLoaderIter'\n",
            " |      # We quote '_BaseDataLoaderIter' since it isn't defined yet and the definition can't be moved up\n",
            " |      # since '_BaseDataLoaderIter' references 'DataLoader'.\n",
            " |  \n",
            " |  __len__(self) -> int\n",
            " |  \n",
            " |  __setattr__(self, attr, val)\n",
            " |      Implement setattr(self, name, value).\n",
            " |  \n",
            " |  check_worker_number_rationality(self)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  multiprocessing_context\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __annotations__ = {'_iterator': typing.Union[ForwardRef('_BaseDataLoad...\n",
            " |  \n",
            " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
            " |  \n",
            " |  __parameters__ = (+T_co,)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from typing.Generic:\n",
            " |  \n",
            " |  __class_getitem__(params) from builtins.type\n",
            " |  \n",
            " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
            " |      This method is called when a class is subclassed.\n",
            " |      \n",
            " |      The default implementation does nothing. It may be\n",
            " |      overridden to extend subclasses.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from typing.Generic:\n",
            " |  \n",
            " |  __new__(cls, *args, **kwds)\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_vsHPV_1TZ-"
      },
      "source": [
        "dataloader = DataLoader(train_iter, batch_size=16, shuffle=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_4z8hD41_fI",
        "outputId": "e8b9e335-e3f1-4090-ec57-e7add21b98fe"
      },
      "source": [
        "next(iter(dataloader))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1]),\n",
              " ('Stuning even for the non-gamer This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^',\n",
              "  \"The best soundtrack ever to anything. I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\",\n",
              "  'Amazing! This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.',\n",
              "  \"Excellent Soundtrack I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Unstealable Jewel.Overall, this is a excellent soundtrack and should be brought by those that like video game music.Xander Cross\",\n",
              "  \"Remember, Pull Your Jaw Off The Floor After Hearing it If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.\",\n",
              "  \"an absolute masterpiece I am quite sure any of you actually taking the time to read this have played the game at least once, and heard at least a few of the tracks here. And whether you were aware of it or not, Mitsuda's music contributed greatly to the mood of every single minute of the whole game.Composed of 3 CDs and quite a few songs (I haven't an exact count), all of which are heart-rendering and impressively remarkable, this soundtrack is one I assure you you will not forget. It has everything for every listener -- from fast-paced and energetic (Dancing the Tokage or Termina Home), to slower and more haunting (Dragon God), to purely beautifully composed (Time's Scar), to even some fantastic vocals (Radical Dreamers).This is one of the best videogame soundtracks out there, and surely Mitsuda's best ever. ^_^\",\n",
              "  'Buyer beware This is a self-published book, and if you want to know why--read a few paragraphs! Those 5 star reviews must have been written by Ms. Haddon\\'s family and friends--or perhaps, by herself! I can\\'t imagine anyone reading the whole thing--I spent an evening with the book and a friend and we were in hysterics reading bits and pieces of it to one another. It is most definitely bad enough to be entered into some kind of a \"worst book\" contest. I can\\'t believe Amazon even sells this kind of thing. Maybe I can offer them my 8th grade term paper on \"To Kill a Mockingbird\"--a book I am quite sure Ms. Haddon never heard of. Anyway, unless you are in a mood to send a book to someone as a joke---stay far, far away from this one!',\n",
              "  'Glorious story I loved Whisper of the wicked saints. The story was amazing and I was pleasantly surprised at the changes in the book. I am not normaly someone who is into romance novels, but the world was raving about this book and so I bought it. I loved it !! This is a brilliant story because it is so true. This book was so wonderful that I have told all of my friends to read it. It is not a typical romance, it is so much more. Not reading this book is a crime, becuase you are missing out on a heart warming story.',\n",
              "  \"A FIVE STAR BOOK I just finished reading Whisper of the Wicked saints. I fell in love with the caracters. I expected an average romance read, but instead I found one of my favorite books of all time. Just when I thought I could predict the outcome I was shocked ! The writting was so descriptive that my heart broke when Julia's did and I felt as if I was there with them instead of just a distant reader. If you are a lover of romance novels then this is a must read. Don't let the cover fool you this book is spectacular!\",\n",
              "  'Whispers of the Wicked Saints This was a easy to read book that made me want to keep reading on and on, not easy to put down.It left me wanting to read the follow on, which I hope is coming soon. I used to read a lot but have gotten away from it. This book made me want to read again. Very enjoyable.',\n",
              "  \"The Worst! A complete waste of time. Typographical errors, poor grammar, and a totally pathetic plot add up to absolutely nothing. I'm embarrassed for this author and very disappointed I actually paid for this book.\",\n",
              "  'Great book This was a great book,I just could not put it down,and could not read it fast enough. Boy what a book the twist and turns in this just keeps you guessing and wanting to know what is going to happen next. This book makes you fall in love and can heat you up,it can also make you so angery. this book can make you go throu several of your emotions. This is a quick read romance. It is something that you will want to end your day off with if you read at night.',\n",
              "  'Great Read I thought this book was brilliant, but yet realistic. It showed me that to error is human. I loved the fact that this writer showed the loving side of God and not the revengeful side of him. I loved how it twisted and turned and I could not put it down. I also loved The glass castle.',\n",
              "  \"Oh please I guess you have to be a romance novel lover for this one, and not a very discerning one. All others beware! It is absolute drivel. I figured I was in trouble when a typo is prominently featured on the back cover, but the first page of the book removed all doubt. Wait - maybe I'm missing the point. A quick re-read of the beginning now makes it clear. This has to be an intentional churning of over-heated prose for satiric purposes. Phew, so glad I didn't waste $10.95 after all.\",\n",
              "  'Awful beyond belief! I feel I have to write to keep others from wasting their money. This book seems to have been written by a 7th grader with poor grammatical skills for her age! As another reviewer points out, there is a misspelling on the cover, and I believe there is at least one per chapter. For example, it was mentioned twice that she had a \"lean\" on her house. I was so distracted by the poor writing and weak plot, that I decided to read with a pencil in hand to mark all of the horrible grammar and spelling. Please don\\'t waste your money. I too, believe that the good reviews must have been written by the author\\'s relatives. I will not put much faith in the reviews from now on!',\n",
              "  \"Don't try to fool us with fake reviews. It's glaringly obvious that all of the glowing reviews have been written by the same person, perhaps the author herself. They all have the same misspellings and poor sentence structure that is featured in the book. Who made Veronica Haddon think she is an author?\")]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq-IuEKY2GQR"
      },
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdxunJbc3FUH",
        "outputId": "0460fc2a-6b77-4082-f789-3b9a70200530"
      },
      "source": [
        "help(get_tokenizer)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function get_tokenizer in module torchtext.data.utils:\n",
            "\n",
            "get_tokenizer(tokenizer, language='en')\n",
            "    Generate tokenizer function for a string sentence.\n",
            "    \n",
            "    Args:\n",
            "        tokenizer: the name of tokenizer function. If None, it returns split()\n",
            "            function, which splits the string sentence by space.\n",
            "            If basic_english, it returns _basic_english_normalize() function,\n",
            "            which normalize the string first and split by space. If a callable\n",
            "            function, it will return the function. If a tokenizer library\n",
            "            (e.g. spacy, moses, toktok, revtok, subword), it returns the\n",
            "            corresponding library.\n",
            "        language: Default en\n",
            "    \n",
            "    Examples:\n",
            "        >>> import torchtext\n",
            "        >>> from torchtext.data import get_tokenizer\n",
            "        >>> tokenizer = get_tokenizer(\"basic_english\")\n",
            "        >>> tokens = tokenizer(\"You can now install TorchText using pip!\")\n",
            "        >>> tokens\n",
            "        >>> ['you', 'can', 'now', 'install', 'torchtext', 'using', 'pip', '!']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_y2YR4UV3GOi"
      },
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNW8jB3h3cay",
        "outputId": "da2c4c58-dfc1-4e5e-d225-ee52ae5e3df6"
      },
      "source": [
        "tokens = tokenizer(\"You can now install TorchText using pip!\")\n",
        "tokens"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['you', 'can', 'now', 'install', 'torchtext', 'using', 'pip', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKg_ePFP3emp",
        "outputId": "e3962e08-274f-4821-a7eb-e654949eef45"
      },
      "source": [
        "help(build_vocab_from_iterator)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function build_vocab_from_iterator in module torchtext.vocab.vocab_factory:\n",
            "\n",
            "build_vocab_from_iterator(iterator: Iterable, min_freq: int = 1, specials: Union[List[str], NoneType] = None, special_first: bool = True) -> torchtext.vocab.vocab.Vocab\n",
            "    Build a Vocab from an iterator.\n",
            "    \n",
            "    Args:\n",
            "        iterator: Iterator used to build Vocab. Must yield list or iterator of tokens.\n",
            "        min_freq: The minimum frequency needed to include a token in the vocabulary.\n",
            "        specials: Special symbols to add. The order of supplied tokens will be preserved.\n",
            "        special_first: Indicates whether to insert symbols at the beginning or at the end.\n",
            "    \n",
            "    \n",
            "    Returns:\n",
            "        torchtext.vocab.Vocab: A `Vocab` object\n",
            "    \n",
            "    Examples:\n",
            "        >>> #generating vocab from text file\n",
            "        >>> import io\n",
            "        >>> from torchtext.vocab import build_vocab_from_iterator\n",
            "        >>> def yield_tokens(file_path):\n",
            "        >>>     with io.open(file_path, encoding = 'utf-8') as f:\n",
            "        >>>         for line in f:\n",
            "        >>>             yield line.strip().split()\n",
            "        >>> vocab = build_vocab_from_iterator(yield_tokens_batch(file_path), specials=[\"<unk>\"])\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oALqqil43mX2"
      },
      "source": [
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "train_iter = AmazonReviewPolarity(split = 'train')\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "  for _, text in data_iter:\n",
        "    yield tokenizer(text)\n",
        "\n",
        "vocab = build_vocab_from_iterator(yield_tokens(train_iter), specials=[\"<unk>\"])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6j3Ug97O6VHX",
        "outputId": "0e6f700c-718b-45a2-b438-2170ea14836a"
      },
      "source": [
        "help(vocab)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on Vocab in module torchtext.vocab.vocab object:\n",
            "\n",
            "class Vocab(torch.nn.modules.module.Module)\n",
            " |  Vocab(vocab)\n",
            " |  \n",
            " |  Base class for all neural network modules.\n",
            " |  \n",
            " |  Your models should also subclass this class.\n",
            " |  \n",
            " |  Modules can also contain other Modules, allowing to nest them in\n",
            " |  a tree structure. You can assign the submodules as regular attributes::\n",
            " |  \n",
            " |      import torch.nn as nn\n",
            " |      import torch.nn.functional as F\n",
            " |  \n",
            " |      class Model(nn.Module):\n",
            " |          def __init__(self):\n",
            " |              super(Model, self).__init__()\n",
            " |              self.conv1 = nn.Conv2d(1, 20, 5)\n",
            " |              self.conv2 = nn.Conv2d(20, 20, 5)\n",
            " |  \n",
            " |          def forward(self, x):\n",
            " |              x = F.relu(self.conv1(x))\n",
            " |              return F.relu(self.conv2(x))\n",
            " |  \n",
            " |  Submodules assigned in this way will be registered, and will have their\n",
            " |  parameters converted too when you call :meth:`to`, etc.\n",
            " |  \n",
            " |  :ivar training: Boolean represents whether this module is in training or\n",
            " |                  evaluation mode.\n",
            " |  :vartype training: bool\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Vocab\n",
            " |      torch.nn.modules.module.Module\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __contains__(self, token: str) -> bool\n",
            " |      Args:\n",
            " |          token: The token for which to check the membership.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Whether the token is member of vocab or not.\n",
            " |  \n",
            " |  __getitem__(self, token: str) -> int\n",
            " |      Args:\n",
            " |          token: The token used to lookup the corresponding index.\n",
            " |      \n",
            " |      Returns:\n",
            " |          The index corresponding to the associated token.\n",
            " |  \n",
            " |  __init__(self, vocab)\n",
            " |      Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
            " |  \n",
            " |  __len__(self) -> int\n",
            " |      Returns:\n",
            " |          The length of the vocab.\n",
            " |  \n",
            " |  __prepare_scriptable__(self)\n",
            " |      Return a JITable Vocab.\n",
            " |  \n",
            " |  append_token(self, token: str) -> None\n",
            " |      Args:\n",
            " |          token: The token used to lookup the corresponding index.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `token` already exists in the vocab\n",
            " |  \n",
            " |  forward(self, tokens: List[str]) -> List[int]\n",
            " |      Calls the `lookup_indices` method\n",
            " |      \n",
            " |      Args:\n",
            " |          tokens: a list of tokens used to lookup their corresponding `indices`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          The indices associated with a list of `tokens`.\n",
            " |  \n",
            " |  get_default_index(self) -> Union[int, NoneType]\n",
            " |      Returns:\n",
            " |          Value of default index if it is set.\n",
            " |  \n",
            " |  get_itos(self) -> List[str]\n",
            " |      Returns:\n",
            " |          List mapping indices to tokens.\n",
            " |  \n",
            " |  get_stoi(self) -> Dict[str, int]\n",
            " |      Returns:\n",
            " |          Dictionary mapping tokens to indices.\n",
            " |  \n",
            " |  insert_token(self, token: str, index: int) -> None\n",
            " |      Args:\n",
            " |          token: The token used to lookup the corresponding index.\n",
            " |          index: The index corresponding to the associated token.\n",
            " |      Raises:\n",
            " |          RuntimeError: If `index` is not in range [0, Vocab.size()] or if `token` already exists in the vocab.\n",
            " |  \n",
            " |  lookup_indices(self, tokens: List[str]) -> List[int]\n",
            " |      Args:\n",
            " |          tokens: the tokens used to lookup their corresponding `indices`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          The 'indices` associated with `tokens`.\n",
            " |  \n",
            " |  lookup_token(self, index: int) -> str\n",
            " |      Args:\n",
            " |          index: The index corresponding to the associated token.\n",
            " |      \n",
            " |      Returns:\n",
            " |          token: The token used to lookup the corresponding index.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If `index` not in range [0, itos.size()).\n",
            " |  \n",
            " |  lookup_tokens(self, indices: List[int]) -> List[str]\n",
            " |      Args:\n",
            " |          indices: The `indices` used to lookup their corresponding`tokens`.\n",
            " |      \n",
            " |      Returns:\n",
            " |          The `tokens` associated with `indices`.\n",
            " |      \n",
            " |      Raises:\n",
            " |          RuntimeError: If an index within `indices` is not int range [0, itos.size()).\n",
            " |  \n",
            " |  set_default_index(self, index: Union[int, NoneType]) -> None\n",
            " |      Args:\n",
            " |          index: Value of default index. This index will be returned when OOV token is queried.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  is_jitable\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __jit_unused_properties__ = ['is_jitable']\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from torch.nn.modules.module.Module:\n",
            " |  \n",
            " |  __call__ = _call_impl(self, *input, **kwargs)\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __dir__(self)\n",
            " |      Default dir() implementation.\n",
            " |  \n",
            " |  __getattr__(self, name: str) -> Union[torch.Tensor, ForwardRef('Module')]\n",
            " |  \n",
            " |  __repr__(self)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __setattr__(self, name: str, value: Union[torch.Tensor, ForwardRef('Module')]) -> None\n",
            " |      Implement setattr(self, name, value).\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  add_module(self, name: str, module: Union[ForwardRef('Module'), NoneType]) -> None\n",
            " |      Adds a child module to the current module.\n",
            " |      \n",
            " |      The module can be accessed as an attribute using the given name.\n",
            " |      \n",
            " |      Args:\n",
            " |          name (string): name of the child module. The child module can be\n",
            " |              accessed from this module using the given name\n",
            " |          module (Module): child module to be added to the module.\n",
            " |  \n",
            " |  apply(self: ~T, fn: Callable[[ForwardRef('Module')], NoneType]) -> ~T\n",
            " |      Applies ``fn`` recursively to every submodule (as returned by ``.children()``)\n",
            " |      as well as self. Typical use includes initializing the parameters of a model\n",
            " |      (see also :ref:`nn-init-doc`).\n",
            " |      \n",
            " |      Args:\n",
            " |          fn (:class:`Module` -> None): function to be applied to each submodule\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> @torch.no_grad()\n",
            " |          >>> def init_weights(m):\n",
            " |          >>>     print(m)\n",
            " |          >>>     if type(m) == nn.Linear:\n",
            " |          >>>         m.weight.fill_(1.0)\n",
            " |          >>>         print(m.weight)\n",
            " |          >>> net = nn.Sequential(nn.Linear(2, 2), nn.Linear(2, 2))\n",
            " |          >>> net.apply(init_weights)\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 1.,  1.],\n",
            " |                  [ 1.,  1.]])\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 1.,  1.],\n",
            " |                  [ 1.,  1.]])\n",
            " |          Sequential(\n",
            " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
            " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
            " |          )\n",
            " |          Sequential(\n",
            " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
            " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
            " |          )\n",
            " |  \n",
            " |  bfloat16(self: ~T) -> ~T\n",
            " |      Casts all floating point parameters and buffers to ``bfloat16`` datatype.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  buffers(self, recurse: bool = True) -> Iterator[torch.Tensor]\n",
            " |      Returns an iterator over module buffers.\n",
            " |      \n",
            " |      Args:\n",
            " |          recurse (bool): if True, then yields buffers of this module\n",
            " |              and all submodules. Otherwise, yields only buffers that\n",
            " |              are direct members of this module.\n",
            " |      \n",
            " |      Yields:\n",
            " |          torch.Tensor: module buffer\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for buf in model.buffers():\n",
            " |          >>>     print(type(buf), buf.size())\n",
            " |          <class 'torch.Tensor'> (20L,)\n",
            " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
            " |  \n",
            " |  children(self) -> Iterator[ForwardRef('Module')]\n",
            " |      Returns an iterator over immediate children modules.\n",
            " |      \n",
            " |      Yields:\n",
            " |          Module: a child module\n",
            " |  \n",
            " |  cpu(self: ~T) -> ~T\n",
            " |      Moves all model parameters and buffers to the CPU.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  cuda(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
            " |      Moves all model parameters and buffers to the GPU.\n",
            " |      \n",
            " |      This also makes associated parameters and buffers different objects. So\n",
            " |      it should be called before constructing optimizer if the module will\n",
            " |      live on GPU while being optimized.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Args:\n",
            " |          device (int, optional): if specified, all parameters will be\n",
            " |              copied to that device\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  double(self: ~T) -> ~T\n",
            " |      Casts all floating point parameters and buffers to ``double`` datatype.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  eval(self: ~T) -> ~T\n",
            " |      Sets the module in evaluation mode.\n",
            " |      \n",
            " |      This has any effect only on certain modules. See documentations of\n",
            " |      particular modules for details of their behaviors in training/evaluation\n",
            " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
            " |      etc.\n",
            " |      \n",
            " |      This is equivalent with :meth:`self.train(False) <torch.nn.Module.train>`.\n",
            " |      \n",
            " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
            " |      `.eval()` and several similar mechanisms that may be confused with it.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  extra_repr(self) -> str\n",
            " |      Set the extra representation of the module\n",
            " |      \n",
            " |      To print customized extra information, you should re-implement\n",
            " |      this method in your own modules. Both single-line and multi-line\n",
            " |      strings are acceptable.\n",
            " |  \n",
            " |  float(self: ~T) -> ~T\n",
            " |      Casts all floating point parameters and buffers to ``float`` datatype.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  get_buffer(self, target: str) -> 'Tensor'\n",
            " |      Returns the buffer given by ``target`` if it exists,\n",
            " |      otherwise throws an error.\n",
            " |      \n",
            " |      See the docstring for ``get_submodule`` for a more detailed\n",
            " |      explanation of this method's functionality as well as how to\n",
            " |      correctly specify ``target``.\n",
            " |      \n",
            " |      Args:\n",
            " |          target: The fully-qualified string name of the buffer\n",
            " |              to look for. (See ``get_submodule`` for how to specify a\n",
            " |              fully-qualified string.)\n",
            " |      \n",
            " |      Returns:\n",
            " |          torch.Tensor: The buffer referenced by ``target``\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: If the target string references an invalid\n",
            " |              path or resolves to something that is not a\n",
            " |              buffer\n",
            " |  \n",
            " |  get_extra_state(self) -> Any\n",
            " |      Returns any extra state to include in the module's state_dict.\n",
            " |      Implement this and a corresponding :func:`set_extra_state` for your module\n",
            " |      if you need to store extra state. This function is called when building the\n",
            " |      module's `state_dict()`.\n",
            " |      \n",
            " |      Note that extra state should be pickleable to ensure working serialization\n",
            " |      of the state_dict. We only provide provide backwards compatibility guarantees\n",
            " |      for serializing Tensors; other objects may break backwards compatibility if\n",
            " |      their serialized pickled form changes.\n",
            " |      \n",
            " |      Returns:\n",
            " |          object: Any extra state to store in the module's state_dict\n",
            " |  \n",
            " |  get_parameter(self, target: str) -> 'Parameter'\n",
            " |      Returns the parameter given by ``target`` if it exists,\n",
            " |      otherwise throws an error.\n",
            " |      \n",
            " |      See the docstring for ``get_submodule`` for a more detailed\n",
            " |      explanation of this method's functionality as well as how to\n",
            " |      correctly specify ``target``.\n",
            " |      \n",
            " |      Args:\n",
            " |          target: The fully-qualified string name of the Parameter\n",
            " |              to look for. (See ``get_submodule`` for how to specify a\n",
            " |              fully-qualified string.)\n",
            " |      \n",
            " |      Returns:\n",
            " |          torch.nn.Parameter: The Parameter referenced by ``target``\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: If the target string references an invalid\n",
            " |              path or resolves to something that is not an\n",
            " |              ``nn.Parameter``\n",
            " |  \n",
            " |  get_submodule(self, target: str) -> 'Module'\n",
            " |      Returns the submodule given by ``target`` if it exists,\n",
            " |      otherwise throws an error.\n",
            " |      \n",
            " |      For example, let's say you have an ``nn.Module`` ``A`` that\n",
            " |      looks like this:\n",
            " |      \n",
            " |      .. code-block::text\n",
            " |      \n",
            " |          A(\n",
            " |              (net_b): Module(\n",
            " |                  (net_c): Module(\n",
            " |                      (conv): Conv2d(16, 33, kernel_size=(3, 3), stride=(2, 2))\n",
            " |                  )\n",
            " |                  (linear): Linear(in_features=100, out_features=200, bias=True)\n",
            " |              )\n",
            " |          )\n",
            " |      \n",
            " |      (The diagram shows an ``nn.Module`` ``A``. ``A`` has a nested\n",
            " |      submodule ``net_b``, which itself has two submodules ``net_c``\n",
            " |      and ``linear``. ``net_c`` then has a submodule ``conv``.)\n",
            " |      \n",
            " |      To check whether or not we have the ``linear`` submodule, we\n",
            " |      would call ``get_submodule(\"net_b.linear\")``. To check whether\n",
            " |      we have the ``conv`` submodule, we would call\n",
            " |      ``get_submodule(\"net_b.net_c.conv\")``.\n",
            " |      \n",
            " |      The runtime of ``get_submodule`` is bounded by the degree\n",
            " |      of module nesting in ``target``. A query against\n",
            " |      ``named_modules`` achieves the same result, but it is O(N) in\n",
            " |      the number of transitive modules. So, for a simple check to see\n",
            " |      if some submodule exists, ``get_submodule`` should always be\n",
            " |      used.\n",
            " |      \n",
            " |      Args:\n",
            " |          target: The fully-qualified string name of the submodule\n",
            " |              to look for. (See above example for how to specify a\n",
            " |              fully-qualified string.)\n",
            " |      \n",
            " |      Returns:\n",
            " |          torch.nn.Module: The submodule referenced by ``target``\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: If the target string references an invalid\n",
            " |              path or resolves to something that is not an\n",
            " |              ``nn.Module``\n",
            " |  \n",
            " |  half(self: ~T) -> ~T\n",
            " |      Casts all floating point parameters and buffers to ``half`` datatype.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  load_state_dict(self, state_dict: 'OrderedDict[str, Tensor]', strict: bool = True)\n",
            " |      Copies parameters and buffers from :attr:`state_dict` into\n",
            " |      this module and its descendants. If :attr:`strict` is ``True``, then\n",
            " |      the keys of :attr:`state_dict` must exactly match the keys returned\n",
            " |      by this module's :meth:`~torch.nn.Module.state_dict` function.\n",
            " |      \n",
            " |      Args:\n",
            " |          state_dict (dict): a dict containing parameters and\n",
            " |              persistent buffers.\n",
            " |          strict (bool, optional): whether to strictly enforce that the keys\n",
            " |              in :attr:`state_dict` match the keys returned by this module's\n",
            " |              :meth:`~torch.nn.Module.state_dict` function. Default: ``True``\n",
            " |      \n",
            " |      Returns:\n",
            " |          ``NamedTuple`` with ``missing_keys`` and ``unexpected_keys`` fields:\n",
            " |              * **missing_keys** is a list of str containing the missing keys\n",
            " |              * **unexpected_keys** is a list of str containing the unexpected keys\n",
            " |      \n",
            " |      Note:\n",
            " |          If a parameter or buffer is registered as ``None`` and its corresponding key\n",
            " |          exists in :attr:`state_dict`, :meth:`load_state_dict` will raise a\n",
            " |          ``RuntimeError``.\n",
            " |  \n",
            " |  modules(self) -> Iterator[ForwardRef('Module')]\n",
            " |      Returns an iterator over all modules in the network.\n",
            " |      \n",
            " |      Yields:\n",
            " |          Module: a module in the network\n",
            " |      \n",
            " |      Note:\n",
            " |          Duplicate modules are returned only once. In the following\n",
            " |          example, ``l`` will be returned only once.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> l = nn.Linear(2, 2)\n",
            " |          >>> net = nn.Sequential(l, l)\n",
            " |          >>> for idx, m in enumerate(net.modules()):\n",
            " |                  print(idx, '->', m)\n",
            " |      \n",
            " |          0 -> Sequential(\n",
            " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
            " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
            " |          )\n",
            " |          1 -> Linear(in_features=2, out_features=2, bias=True)\n",
            " |  \n",
            " |  named_buffers(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.Tensor]]\n",
            " |      Returns an iterator over module buffers, yielding both the\n",
            " |      name of the buffer as well as the buffer itself.\n",
            " |      \n",
            " |      Args:\n",
            " |          prefix (str): prefix to prepend to all buffer names.\n",
            " |          recurse (bool): if True, then yields buffers of this module\n",
            " |              and all submodules. Otherwise, yields only buffers that\n",
            " |              are direct members of this module.\n",
            " |      \n",
            " |      Yields:\n",
            " |          (string, torch.Tensor): Tuple containing the name and buffer\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for name, buf in self.named_buffers():\n",
            " |          >>>    if name in ['running_var']:\n",
            " |          >>>        print(buf.size())\n",
            " |  \n",
            " |  named_children(self) -> Iterator[Tuple[str, ForwardRef('Module')]]\n",
            " |      Returns an iterator over immediate children modules, yielding both\n",
            " |      the name of the module as well as the module itself.\n",
            " |      \n",
            " |      Yields:\n",
            " |          (string, Module): Tuple containing a name and child module\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for name, module in model.named_children():\n",
            " |          >>>     if name in ['conv4', 'conv5']:\n",
            " |          >>>         print(module)\n",
            " |  \n",
            " |  named_modules(self, memo: Union[Set[ForwardRef('Module')], NoneType] = None, prefix: str = '', remove_duplicate: bool = True)\n",
            " |      Returns an iterator over all modules in the network, yielding\n",
            " |      both the name of the module as well as the module itself.\n",
            " |      \n",
            " |      Args:\n",
            " |          memo: a memo to store the set of modules already added to the result\n",
            " |          prefix: a prefix that will be added to the name of the module\n",
            " |          remove_duplicate: whether to remove the duplicated module instances in the result\n",
            " |          or not\n",
            " |      \n",
            " |      Yields:\n",
            " |          (string, Module): Tuple of name and module\n",
            " |      \n",
            " |      Note:\n",
            " |          Duplicate modules are returned only once. In the following\n",
            " |          example, ``l`` will be returned only once.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> l = nn.Linear(2, 2)\n",
            " |          >>> net = nn.Sequential(l, l)\n",
            " |          >>> for idx, m in enumerate(net.named_modules()):\n",
            " |                  print(idx, '->', m)\n",
            " |      \n",
            " |          0 -> ('', Sequential(\n",
            " |            (0): Linear(in_features=2, out_features=2, bias=True)\n",
            " |            (1): Linear(in_features=2, out_features=2, bias=True)\n",
            " |          ))\n",
            " |          1 -> ('0', Linear(in_features=2, out_features=2, bias=True))\n",
            " |  \n",
            " |  named_parameters(self, prefix: str = '', recurse: bool = True) -> Iterator[Tuple[str, torch.nn.parameter.Parameter]]\n",
            " |      Returns an iterator over module parameters, yielding both the\n",
            " |      name of the parameter as well as the parameter itself.\n",
            " |      \n",
            " |      Args:\n",
            " |          prefix (str): prefix to prepend to all parameter names.\n",
            " |          recurse (bool): if True, then yields parameters of this module\n",
            " |              and all submodules. Otherwise, yields only parameters that\n",
            " |              are direct members of this module.\n",
            " |      \n",
            " |      Yields:\n",
            " |          (string, Parameter): Tuple containing the name and parameter\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for name, param in self.named_parameters():\n",
            " |          >>>    if name in ['bias']:\n",
            " |          >>>        print(param.size())\n",
            " |  \n",
            " |  parameters(self, recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter]\n",
            " |      Returns an iterator over module parameters.\n",
            " |      \n",
            " |      This is typically passed to an optimizer.\n",
            " |      \n",
            " |      Args:\n",
            " |          recurse (bool): if True, then yields parameters of this module\n",
            " |              and all submodules. Otherwise, yields only parameters that\n",
            " |              are direct members of this module.\n",
            " |      \n",
            " |      Yields:\n",
            " |          Parameter: module parameter\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> for param in model.parameters():\n",
            " |          >>>     print(type(param), param.size())\n",
            " |          <class 'torch.Tensor'> (20L,)\n",
            " |          <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
            " |  \n",
            " |  register_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
            " |      Registers a backward hook on the module.\n",
            " |      \n",
            " |      This function is deprecated in favor of :meth:`~torch.nn.Module.register_full_backward_hook` and\n",
            " |      the behavior of this function will change in future versions.\n",
            " |      \n",
            " |      Returns:\n",
            " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            " |              a handle that can be used to remove the added hook by calling\n",
            " |              ``handle.remove()``\n",
            " |  \n",
            " |  register_buffer(self, name: str, tensor: Union[torch.Tensor, NoneType], persistent: bool = True) -> None\n",
            " |      Adds a buffer to the module.\n",
            " |      \n",
            " |      This is typically used to register a buffer that should not to be\n",
            " |      considered a model parameter. For example, BatchNorm's ``running_mean``\n",
            " |      is not a parameter, but is part of the module's state. Buffers, by\n",
            " |      default, are persistent and will be saved alongside parameters. This\n",
            " |      behavior can be changed by setting :attr:`persistent` to ``False``. The\n",
            " |      only difference between a persistent buffer and a non-persistent buffer\n",
            " |      is that the latter will not be a part of this module's\n",
            " |      :attr:`state_dict`.\n",
            " |      \n",
            " |      Buffers can be accessed as attributes using given names.\n",
            " |      \n",
            " |      Args:\n",
            " |          name (string): name of the buffer. The buffer can be accessed\n",
            " |              from this module using the given name\n",
            " |          tensor (Tensor or None): buffer to be registered. If ``None``, then operations\n",
            " |              that run on buffers, such as :attr:`cuda`, are ignored. If ``None``,\n",
            " |              the buffer is **not** included in the module's :attr:`state_dict`.\n",
            " |          persistent (bool): whether the buffer is part of this module's\n",
            " |              :attr:`state_dict`.\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> self.register_buffer('running_mean', torch.zeros(num_features))\n",
            " |  \n",
            " |  register_forward_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            " |      Registers a forward hook on the module.\n",
            " |      \n",
            " |      The hook will be called every time after :func:`forward` has computed an output.\n",
            " |      It should have the following signature::\n",
            " |      \n",
            " |          hook(module, input, output) -> None or modified output\n",
            " |      \n",
            " |      The input contains only the positional arguments given to the module.\n",
            " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
            " |      The hook can modify the output. It can modify the input inplace but\n",
            " |      it will not have effect on forward since this is called after\n",
            " |      :func:`forward` is called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            " |              a handle that can be used to remove the added hook by calling\n",
            " |              ``handle.remove()``\n",
            " |  \n",
            " |  register_forward_pre_hook(self, hook: Callable[..., NoneType]) -> torch.utils.hooks.RemovableHandle\n",
            " |      Registers a forward pre-hook on the module.\n",
            " |      \n",
            " |      The hook will be called every time before :func:`forward` is invoked.\n",
            " |      It should have the following signature::\n",
            " |      \n",
            " |          hook(module, input) -> None or modified input\n",
            " |      \n",
            " |      The input contains only the positional arguments given to the module.\n",
            " |      Keyword arguments won't be passed to the hooks and only to the ``forward``.\n",
            " |      The hook can modify the input. User can either return a tuple or a\n",
            " |      single modified value in the hook. We will wrap the value into a tuple\n",
            " |      if a single value is returned(unless that value is already a tuple).\n",
            " |      \n",
            " |      Returns:\n",
            " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            " |              a handle that can be used to remove the added hook by calling\n",
            " |              ``handle.remove()``\n",
            " |  \n",
            " |  register_full_backward_hook(self, hook: Callable[[ForwardRef('Module'), Union[Tuple[torch.Tensor, ...], torch.Tensor], Union[Tuple[torch.Tensor, ...], torch.Tensor]], Union[NoneType, torch.Tensor]]) -> torch.utils.hooks.RemovableHandle\n",
            " |      Registers a backward hook on the module.\n",
            " |      \n",
            " |      The hook will be called every time the gradients with respect to module\n",
            " |      inputs are computed. The hook should have the following signature::\n",
            " |      \n",
            " |          hook(module, grad_input, grad_output) -> tuple(Tensor) or None\n",
            " |      \n",
            " |      The :attr:`grad_input` and :attr:`grad_output` are tuples that contain the gradients\n",
            " |      with respect to the inputs and outputs respectively. The hook should\n",
            " |      not modify its arguments, but it can optionally return a new gradient with\n",
            " |      respect to the input that will be used in place of :attr:`grad_input` in\n",
            " |      subsequent computations. :attr:`grad_input` will only correspond to the inputs given\n",
            " |      as positional arguments and all kwarg arguments are ignored. Entries\n",
            " |      in :attr:`grad_input` and :attr:`grad_output` will be ``None`` for all non-Tensor\n",
            " |      arguments.\n",
            " |      \n",
            " |      For technical reasons, when this hook is applied to a Module, its forward function will\n",
            " |      receive a view of each Tensor passed to the Module. Similarly the caller will receive a view\n",
            " |      of each Tensor returned by the Module's forward function.\n",
            " |      \n",
            " |      .. warning ::\n",
            " |          Modifying inputs or outputs inplace is not allowed when using backward hooks and\n",
            " |          will raise an error.\n",
            " |      \n",
            " |      Returns:\n",
            " |          :class:`torch.utils.hooks.RemovableHandle`:\n",
            " |              a handle that can be used to remove the added hook by calling\n",
            " |              ``handle.remove()``\n",
            " |  \n",
            " |  register_parameter(self, name: str, param: Union[torch.nn.parameter.Parameter, NoneType]) -> None\n",
            " |      Adds a parameter to the module.\n",
            " |      \n",
            " |      The parameter can be accessed as an attribute using given name.\n",
            " |      \n",
            " |      Args:\n",
            " |          name (string): name of the parameter. The parameter can be accessed\n",
            " |              from this module using the given name\n",
            " |          param (Parameter or None): parameter to be added to the module. If\n",
            " |              ``None``, then operations that run on parameters, such as :attr:`cuda`,\n",
            " |              are ignored. If ``None``, the parameter is **not** included in the\n",
            " |              module's :attr:`state_dict`.\n",
            " |  \n",
            " |  requires_grad_(self: ~T, requires_grad: bool = True) -> ~T\n",
            " |      Change if autograd should record operations on parameters in this\n",
            " |      module.\n",
            " |      \n",
            " |      This method sets the parameters' :attr:`requires_grad` attributes\n",
            " |      in-place.\n",
            " |      \n",
            " |      This method is helpful for freezing part of the module for finetuning\n",
            " |      or training parts of a model individually (e.g., GAN training).\n",
            " |      \n",
            " |      See :ref:`locally-disable-grad-doc` for a comparison between\n",
            " |      `.requires_grad_()` and several similar mechanisms that may be confused with it.\n",
            " |      \n",
            " |      Args:\n",
            " |          requires_grad (bool): whether autograd should record operations on\n",
            " |                                parameters in this module. Default: ``True``.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  set_extra_state(self, state: Any)\n",
            " |      This function is called from :func:`load_state_dict` to handle any extra state\n",
            " |      found within the `state_dict`. Implement this function and a corresponding\n",
            " |      :func:`get_extra_state` for your module if you need to store extra state within its\n",
            " |      `state_dict`.\n",
            " |      \n",
            " |      Args:\n",
            " |          state (dict): Extra state from the `state_dict`\n",
            " |  \n",
            " |  share_memory(self: ~T) -> ~T\n",
            " |      See :meth:`torch.Tensor.share_memory_`\n",
            " |  \n",
            " |  state_dict(self, destination=None, prefix='', keep_vars=False)\n",
            " |      Returns a dictionary containing a whole state of the module.\n",
            " |      \n",
            " |      Both parameters and persistent buffers (e.g. running averages) are\n",
            " |      included. Keys are corresponding parameter and buffer names.\n",
            " |      Parameters and buffers set to ``None`` are not included.\n",
            " |      \n",
            " |      Returns:\n",
            " |          dict:\n",
            " |              a dictionary containing a whole state of the module\n",
            " |      \n",
            " |      Example::\n",
            " |      \n",
            " |          >>> module.state_dict().keys()\n",
            " |          ['bias', 'weight']\n",
            " |  \n",
            " |  to(self, *args, **kwargs)\n",
            " |      Moves and/or casts the parameters and buffers.\n",
            " |      \n",
            " |      This can be called as\n",
            " |      \n",
            " |      .. function:: to(device=None, dtype=None, non_blocking=False)\n",
            " |         :noindex:\n",
            " |      \n",
            " |      .. function:: to(dtype, non_blocking=False)\n",
            " |         :noindex:\n",
            " |      \n",
            " |      .. function:: to(tensor, non_blocking=False)\n",
            " |         :noindex:\n",
            " |      \n",
            " |      .. function:: to(memory_format=torch.channels_last)\n",
            " |         :noindex:\n",
            " |      \n",
            " |      Its signature is similar to :meth:`torch.Tensor.to`, but only accepts\n",
            " |      floating point or complex :attr:`dtype`\\ s. In addition, this method will\n",
            " |      only cast the floating point or complex parameters and buffers to :attr:`dtype`\n",
            " |      (if given). The integral parameters and buffers will be moved\n",
            " |      :attr:`device`, if that is given, but with dtypes unchanged. When\n",
            " |      :attr:`non_blocking` is set, it tries to convert/move asynchronously\n",
            " |      with respect to the host if possible, e.g., moving CPU Tensors with\n",
            " |      pinned memory to CUDA devices.\n",
            " |      \n",
            " |      See below for examples.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Args:\n",
            " |          device (:class:`torch.device`): the desired device of the parameters\n",
            " |              and buffers in this module\n",
            " |          dtype (:class:`torch.dtype`): the desired floating point or complex dtype of\n",
            " |              the parameters and buffers in this module\n",
            " |          tensor (torch.Tensor): Tensor whose dtype and device are the desired\n",
            " |              dtype and device for all parameters and buffers in this module\n",
            " |          memory_format (:class:`torch.memory_format`): the desired memory\n",
            " |              format for 4D parameters and buffers in this module (keyword\n",
            " |              only argument)\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |      \n",
            " |      Examples::\n",
            " |      \n",
            " |          >>> linear = nn.Linear(2, 2)\n",
            " |          >>> linear.weight\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 0.1913, -0.3420],\n",
            " |                  [-0.5113, -0.2325]])\n",
            " |          >>> linear.to(torch.double)\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          >>> linear.weight\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 0.1913, -0.3420],\n",
            " |                  [-0.5113, -0.2325]], dtype=torch.float64)\n",
            " |          >>> gpu1 = torch.device(\"cuda:1\")\n",
            " |          >>> linear.to(gpu1, dtype=torch.half, non_blocking=True)\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          >>> linear.weight\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 0.1914, -0.3420],\n",
            " |                  [-0.5112, -0.2324]], dtype=torch.float16, device='cuda:1')\n",
            " |          >>> cpu = torch.device(\"cpu\")\n",
            " |          >>> linear.to(cpu)\n",
            " |          Linear(in_features=2, out_features=2, bias=True)\n",
            " |          >>> linear.weight\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 0.1914, -0.3420],\n",
            " |                  [-0.5112, -0.2324]], dtype=torch.float16)\n",
            " |      \n",
            " |          >>> linear = nn.Linear(2, 2, bias=None).to(torch.cdouble)\n",
            " |          >>> linear.weight\n",
            " |          Parameter containing:\n",
            " |          tensor([[ 0.3741+0.j,  0.2382+0.j],\n",
            " |                  [ 0.5593+0.j, -0.4443+0.j]], dtype=torch.complex128)\n",
            " |          >>> linear(torch.ones(3, 2, dtype=torch.cdouble))\n",
            " |          tensor([[0.6122+0.j, 0.1150+0.j],\n",
            " |                  [0.6122+0.j, 0.1150+0.j],\n",
            " |                  [0.6122+0.j, 0.1150+0.j]], dtype=torch.complex128)\n",
            " |  \n",
            " |  to_empty(self: ~T, *, device: Union[str, torch.device]) -> ~T\n",
            " |      Moves the parameters and buffers to the specified device without copying storage.\n",
            " |      \n",
            " |      Args:\n",
            " |          device (:class:`torch.device`): The desired device of the parameters\n",
            " |              and buffers in this module.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  train(self: ~T, mode: bool = True) -> ~T\n",
            " |      Sets the module in training mode.\n",
            " |      \n",
            " |      This has any effect only on certain modules. See documentations of\n",
            " |      particular modules for details of their behaviors in training/evaluation\n",
            " |      mode, if they are affected, e.g. :class:`Dropout`, :class:`BatchNorm`,\n",
            " |      etc.\n",
            " |      \n",
            " |      Args:\n",
            " |          mode (bool): whether to set training mode (``True``) or evaluation\n",
            " |                       mode (``False``). Default: ``True``.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  type(self: ~T, dst_type: Union[torch.dtype, str]) -> ~T\n",
            " |      Casts all parameters and buffers to :attr:`dst_type`.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Args:\n",
            " |          dst_type (type or string): the desired type\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  xpu(self: ~T, device: Union[int, torch.device, NoneType] = None) -> ~T\n",
            " |      Moves all model parameters and buffers to the XPU.\n",
            " |      \n",
            " |      This also makes associated parameters and buffers different objects. So\n",
            " |      it should be called before constructing optimizer if the module will\n",
            " |      live on XPU while being optimized.\n",
            " |      \n",
            " |      .. note::\n",
            " |          This method modifies the module in-place.\n",
            " |      \n",
            " |      Arguments:\n",
            " |          device (int, optional): if specified, all parameters will be\n",
            " |              copied to that device\n",
            " |      \n",
            " |      Returns:\n",
            " |          Module: self\n",
            " |  \n",
            " |  zero_grad(self, set_to_none: bool = False) -> None\n",
            " |      Sets gradients of all model parameters to zero. See similar function\n",
            " |      under :class:`torch.optim.Optimizer` for more context.\n",
            " |      \n",
            " |      Args:\n",
            " |          set_to_none (bool): instead of setting to zero, set the grads to None.\n",
            " |              See :meth:`torch.optim.Optimizer.zero_grad` for details.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from torch.nn.modules.module.Module:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from torch.nn.modules.module.Module:\n",
            " |  \n",
            " |  T_destination = ~T_destination\n",
            " |  \n",
            " |  __annotations__ = {'__call__': typing.Callable[..., typing.Any], '_is_...\n",
            " |  \n",
            " |  dump_patches = False\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6Cp7Qbw6xS1"
      },
      "source": [
        "vocab.set_default_index(vocab[\"<unk>\"])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OKrep6I7JqF",
        "outputId": "aedf7835-d6dd-4e28-829f-e3803f4052d1"
      },
      "source": [
        "vocab(['here', 'is', 'an', 'example', 'of', 'alien', 'invasion', 'they', 'are', 'called', 'bangalorites'])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[196, 12, 49, 715, 9, 2894, 7076, 36, 29, 532, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQVgPe4P7Xef",
        "outputId": "ccc25521-d080-42b6-a93f-a6d22758338d"
      },
      "source": [
        "vocab[\"<unk>\"]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK1sxfsM7doh"
      },
      "source": [
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "label_pipeline = lambda x: int(x) - 1"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iiJdwCO79Yx",
        "outputId": "8a336669-61b1-4590-8241-34b974d2cbb3"
      },
      "source": [
        "text_pipeline(\"Here is an exmaple of alient invasion, and they are called bangaloriters\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[196, 12, 49, 86649, 9, 363749, 7076, 3, 5, 36, 29, 532, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TQusm2u8COn",
        "outputId": "05523f35-7974-417c-bd8d-e4ee825c2db9"
      },
      "source": [
        "label_pipeline('19')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xArz2o1P8MKG"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def collate_fn(batch):\n",
        "  src_batch, tgt_batch = [], []\n",
        "  for src_batch, tgt_batch in batch:\n",
        "    src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip('\\n')))\n",
        "    tgt_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip('\\n')))\n",
        "  src_batch = pad_sequences(src_batch, padding_value=PAD_IDX)\n",
        "  tgt_batch = pad_sequences(tgt_batch, padding_value=PAD_IDX)\n",
        "  return src_batch, tgt_batch"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFbwLqoN9K9p",
        "outputId": "c854d8e4-410d-4033-e073-8a5f2638e2c0"
      },
      "source": [
        "weight = torch.randn(10, 5)\n",
        "weight"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.5913, -0.9226, -0.4474, -1.4173, -1.0275],\n",
              "        [-1.6253,  0.8147, -1.2453, -1.1690, -0.4868],\n",
              "        [-0.5289, -0.3009,  0.0579, -1.0222, -0.5530],\n",
              "        [-1.3009,  0.2044,  0.2302,  0.5459,  1.2826],\n",
              "        [-0.7907, -1.6150,  1.1316,  1.2925, -0.0509],\n",
              "        [ 1.4463, -0.2989, -0.7461,  0.4186, -1.7536],\n",
              "        [ 0.8327, -0.1156, -0.1755, -0.9057, -0.9442],\n",
              "        [ 0.0363, -1.2857, -0.0352,  1.0292,  0.3943],\n",
              "        [ 0.5716,  0.3841,  0.9985,  0.2207, -0.8201],\n",
              "        [-0.6137,  1.4114,  1.2859,  1.0841, -0.1835]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCobVaQ49umS",
        "outputId": "db0aabbb-507f-4a8b-dc55-b36fb13633ef"
      },
      "source": [
        "indices = torch.tensor([4, 1, 7])\n",
        "indices"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([4, 1, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0texNYh90c6",
        "outputId": "88cce42d-62a7-42ee-a339-2753d2158328"
      },
      "source": [
        "embeddings = torch.nn.functional.embedding(indices, weight)\n",
        "embeddings"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7907, -1.6150,  1.1316,  1.2925, -0.0509],\n",
              "        [-1.6253,  0.8147, -1.2453, -1.1690, -0.4868],\n",
              "        [ 0.0363, -1.2857, -0.0352,  1.0292,  0.3943]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1z-FVN19_VW",
        "outputId": "0ddacb99-0838-4e7c-a592-de97bbb7a6cf"
      },
      "source": [
        "embeddings.mean(dim=0, keepdim=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7932, -0.6953, -0.0496,  0.3842, -0.0478]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrS2kb8p-i1Q",
        "outputId": "bf6ea766-f4d9-4032-861d-fb76642b06e6"
      },
      "source": [
        "torch.nn.functional.embedding_bag(indices, weight, torch.tensor([0]), mode=\"mean\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.7932, -0.6953, -0.0496,  0.3842, -0.0478]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSeLl_Sh-6ON"
      },
      "source": [
        "def collate_batch(batch):\n",
        "    label_list, text_list, offsets = [], [], [0]\n",
        "    for (_label, _text) in batch:\n",
        "         label_list.append(label_pipeline(_label))\n",
        "         processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
        "         text_list.append(processed_text)\n",
        "         offsets.append(processed_text.size(0))\n",
        "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
        "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
        "    text_list = torch.cat(text_list)\n",
        "    return label_list.to(device), text_list.to(device), offsets.to(device)    "
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRDpOkXiAqyo"
      },
      "source": [
        "train_iter = AmazonReviewPolarity(split='train')\n",
        "dataloader = DataLoader(train_iter, batch_size=8, shuffle=False, collate_fn=collate_batch)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-IOBmF7A1N-"
      },
      "source": [
        "from torch import nn\n",
        "\n",
        "class TextClassificationModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text, offsets):\n",
        "        embedded = self.embedding(text, offsets)\n",
        "        return self.fc(embedded)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKuQGv-xBIC1"
      },
      "source": [
        "1: Negative, 2: Positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW1rS0OYBGhR"
      },
      "source": [
        "train_iter = AmazonReviewPolarity(split='train')\n",
        "num_class = len(set([label for (label, text) in train_iter]))\n",
        "vocab_size = len(vocab)\n",
        "emsize = 64\n",
        "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtVCypgvBQfM"
      },
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train(dataloader):\n",
        "    model.train()\n",
        "    total_acc, total_count = 0, 0\n",
        "    log_interval = 500\n",
        "    start_time = time.time()\n",
        "\n",
        "\n",
        "    pbar = tqdm(dataloader)\n",
        "\n",
        "    for idx, (label, text, offsets) in enumerate(pbar):\n",
        "        optimizer.zero_grad()\n",
        "        predited_label = model(text, offsets)\n",
        "        loss = criterion(predited_label, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1) \n",
        "        optimizer.step()\n",
        "        total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "        total_count += label.size(0)\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            # print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
        "            #       '| accuracy {:8.3f}'.format(epoch, idx, len(dataloader),\n",
        "            #                                   total_acc/total_count))\n",
        "            pbar.set_description(desc= f'epoch= {epoch} Accuracy={total_acc/total_count} batch_id={idx}')\n",
        "            total_acc, total_count = 0, 0\n",
        "            start_time = time.time()\n",
        "    return total_acc/total_count\n",
        "\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predited_label = model(text, offsets)\n",
        "            loss = criterion(predited_label, label)\n",
        "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "    return total_acc/total_count"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNg1NgBGhKnc"
      },
      "source": [
        "def classwise_accuracy(dataloader,num_classes):\n",
        "    model.eval()\n",
        "    total_acc, total_count = 0, 0\n",
        "\n",
        "    classwise_predictions = {}\n",
        "    classwise_labels = {}\n",
        "\n",
        "    for i in range(num_classes):\n",
        "        classwise_predictions[i] = 0\n",
        "        classwise_labels[i] = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for idx, (label, text, offsets) in enumerate(dataloader):\n",
        "            predited_label = model(text, offsets)\n",
        "            loss = criterion(predited_label, label)\n",
        "            \n",
        "            total_acc += (predited_label.argmax(1) == label).sum().item()\n",
        "            total_count += label.size(0)\n",
        "            \n",
        "            predictions = predited_label.argmax(1)\n",
        "            for i,class_label in enumerate(label):\n",
        "                classwise_labels[class_label.item()]+=1\n",
        "                if predictions[i].item() == class_label.item():\n",
        "                    classwise_predictions[predictions[i].item()]+=1\n",
        "\n",
        "    classwise_accuracies = {}\n",
        "    for class_label in classwise_labels:\n",
        "        classwise_accuracies[class_label ] = classwise_predictions[class_label]/classwise_labels[class_label]\n",
        "        \n",
        "\n",
        "    for idx, (class_label, acc) in enumerate(classwise_accuracies.items()):\n",
        "        print('Accuracy of Class %s : %.2f %%' % (class_label+1, 100 * acc))\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eV7lPedpBfpS",
        "outputId": "75674b72-c4e3-4ce2-f28a-c1f7c728255f"
      },
      "source": [
        "from torch.utils.data.dataset import random_split\n",
        "from torchtext.data.functional import to_map_style_dataset\n",
        "\n",
        "\n",
        "# Hyperparameters\n",
        "EPOCHS = 10 # epoch\n",
        "LR = 5  # learning rate\n",
        "BATCH_SIZE = 64 # batch size for training\n",
        "  \n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
        "total_accu = None\n",
        "train_iter, test_iter = AmazonReviewPolarity()\n",
        "train_dataset = to_map_style_dataset(train_iter)\n",
        "test_dataset = to_map_style_dataset(test_iter)\n",
        "num_train = int(len(train_dataset) * 0.95)\n",
        "split_train_, split_valid_ = \\\n",
        "    random_split(train_dataset, [num_train, len(train_dataset) - num_train])\n",
        "\n",
        "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE,\n",
        "                              shuffle=True, collate_fn=collate_batch)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n",
        "                             shuffle=True, collate_fn=collate_batch)\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train_acc = train(train_dataloader)\n",
        "    accu_val = evaluate(valid_dataloader)\n",
        "\n",
        "    train_accuracies.append(train_acc)\n",
        "    val_accuracies.append(accu_val)\n",
        "\n",
        "    if total_accu is not None and total_accu > accu_val:\n",
        "      scheduler.step()\n",
        "    else:\n",
        "       total_accu = accu_val\n",
        "  \n",
        "    print('valid accuracy {:8.3f} '.format(accu_val))\n",
        "    "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch= 1 Accuracy=0.89859375 batch_id=53000: 100%|██████████| 53438/53438 [06:43<00:00, 132.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid accuracy    0.902 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch= 2 Accuracy=0.90403125 batch_id=53000: 100%|██████████| 53438/53438 [06:54<00:00, 129.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid accuracy    0.906 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch= 3 Accuracy=0.90425 batch_id=53000: 100%|██████████| 53438/53438 [06:41<00:00, 133.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid accuracy    0.908 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch= 4 Accuracy=0.90965625 batch_id=53000: 100%|██████████| 53438/53438 [06:41<00:00, 133.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid accuracy    0.904 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch= 5 Accuracy=0.9171875 batch_id=53000: 100%|██████████| 53438/53438 [06:40<00:00, 133.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid accuracy    0.910 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch= 6 Accuracy=0.91109375 batch_id=53000: 100%|██████████| 53438/53438 [06:42<00:00, 132.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid accuracy    0.911 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch= 7 Accuracy=0.91721875 batch_id=53000: 100%|██████████| 53438/53438 [06:40<00:00, 133.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid accuracy    0.910 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch= 8 Accuracy=0.91415625 batch_id=53000: 100%|██████████| 53438/53438 [06:40<00:00, 133.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid accuracy    0.911 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch= 9 Accuracy=0.9158125 batch_id=53000: 100%|██████████| 53438/53438 [06:46<00:00, 131.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid accuracy    0.911 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch= 10 Accuracy=0.9146875 batch_id=53000: 100%|██████████| 53438/53438 [06:39<00:00, 133.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "valid accuracy    0.911 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fkd1PY_jIeHn"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "7sCs_8x_IB2j",
        "outputId": "05b7ce7b-1ac2-4315-9e8c-c52247bd47ce"
      },
      "source": [
        "fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "axs[0].plot(train_accuracies)\n",
        "axs[0].set_title(\"Training Accuracy\")\n",
        "axs[1].plot(val_accuracies)\n",
        "axs[1].set_title(\"Validation Accuracy\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Validation Accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUrnPMhVBlq9",
        "outputId": "dcd99277-c58a-484b-b338-07b644613fde"
      },
      "source": [
        "print('Checking the results of test dataset.')\n",
        "accu_test = evaluate(test_dataloader)\n",
        "print('Test Accuracy {:8.2f}'.format(accu_test*100))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking the results of test dataset.\n",
            "Test Accuracy    91.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eal_OIzEnzG5",
        "outputId": "100ed406-e1b0-4ee8-c424-9391f2f9aa00"
      },
      "source": [
        "print('Class-wise Test Accuracy:')\n",
        "classwise_accuracy(test_dataloader,2)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class-wise Test Accuracy:\n",
            "Accuracy of Class 1 : 90.98 %\n",
            "Accuracy of Class 2 : 91.25 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76PGhuKbB4BN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70697e2c-969b-4260-ba6c-6f740c7cd421"
      },
      "source": [
        "amazon_reviews_label = {1: \"Negative\",\n",
        "                 2: \"Positive\"}\n",
        "\n",
        "def predict(text, text_pipeline):\n",
        "    with torch.no_grad():\n",
        "        text = torch.tensor(text_pipeline(text))\n",
        "        output = model(text, torch.tensor([0]))\n",
        "        return output.argmax(1).item() + 1\n",
        "\n",
        "ex_text_str = \"This was a good product\"\n",
        "\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "print(\"%s\" %amazon_reviews_label[predict(ex_text_str, text_pipeline)])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive\n"
          ]
        }
      ]
    }
  ]
}