{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"END2.0 Session 1.ipynb","provenance":[{"file_id":"https://github.com/m-shilpa/END3/blob/main/Session%201%20-%20Background%20%26%20Very%20Basics/Session_1.ipynb","timestamp":1632505271056}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Z2jzymRAnOB7","executionInfo":{"status":"ok","timestamp":1632537411909,"user_tz":-330,"elapsed":17,"user":{"displayName":"Raja Rajendran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17503276241617911432"}}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gkMYI9HWna-p"},"source":["Assignment:\n","\n","Rewrite the Colab file and:\n","\n","remove the last activation function\n","\n","make sure there are in total 44 parameters\n","\n","run it for 2001 epochs\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GC_6PeobwwkH","executionInfo":{"status":"ok","timestamp":1632537413618,"user_tz":-330,"elapsed":1722,"user":{"displayName":"Raja Rajendran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17503276241617911432"}},"outputId":"fc074306-922b-4df2-fce8-54651ae29db3"},"source":["import torch\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","torch.manual_seed(2)"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fa1e1050c90>"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"bL64bMTkw2GP","executionInfo":{"status":"ok","timestamp":1632537413620,"user_tz":-330,"elapsed":25,"user":{"displayName":"Raja Rajendran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17503276241617911432"}}},"source":["# these are the possible inputs to XOR function\n","X = torch.Tensor([[0,0], [0,1], [1,0], [1,1]])\n","# these are the corresponding outputs from the XOR function, for the above inputs \n","Y = torch.Tensor([0, 1, 1, 0]).view(-1,1)"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"aC82kEAIw3Wf","executionInfo":{"status":"ok","timestamp":1632537413625,"user_tz":-330,"elapsed":28,"user":{"displayName":"Raja Rajendran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17503276241617911432"}}},"source":["# NN that models the XOR operation\n","class XOR(nn.Module):\n","    def __init__(self, input_dim = 2, output_dim=1):\n","        super(XOR, self).__init__()\n","        # first linear layer: input=2, number of neurons in this layer=5\n","        self.lin1 = nn.Linear(input_dim, 5)\n","        # second linear layer: input=5, number of neurons in this layer=3\n","        self.lin2 = nn.Linear(5, 3)\n","        # third linear layer: input=3, number of neurons in this layer=2\n","        self.lin3 = nn.Linear(3, 2)\n","        # fourth linear layer: input=2, number of neurons in this layer=1\n","        self.lin4 = nn.Linear(2, output_dim)\n","    \n","    def forward(self, x):\n","        x = self.lin1(x)\n","        x = F.tanh(x)\n","        x = self.lin2(x)\n","        x = F.tanh(x)\n","        x = self.lin3(x)\n","        x = F.tanh(x)\n","        x = self.lin4(x)\n","        #x = F.tanh(x). removed last activation function.\n","        return x"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8gQIQExYw65K","executionInfo":{"status":"ok","timestamp":1632537413626,"user_tz":-330,"elapsed":27,"user":{"displayName":"Raja Rajendran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17503276241617911432"}},"outputId":"95394c4a-cc13-4c1e-b31e-a0e84ddb8e5b"},"source":["# instantiate the model and print the model summary\n","model = XOR()\n","print(model)\n","from torchsummary import summary\n","summary(model, (2,2))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["XOR(\n","  (lin1): Linear(in_features=2, out_features=5, bias=True)\n","  (lin2): Linear(in_features=5, out_features=3, bias=True)\n","  (lin3): Linear(in_features=3, out_features=2, bias=True)\n","  (lin4): Linear(in_features=2, out_features=1, bias=True)\n",")\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Linear-1                 [-1, 2, 5]              15\n","            Linear-2                 [-1, 2, 3]              18\n","            Linear-3                 [-1, 2, 2]               8\n","            Linear-4                 [-1, 2, 1]               3\n","================================================================\n","Total params: 44\n","Trainable params: 44\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.00\n","Params size (MB): 0.00\n","Estimated Total Size (MB): 0.00\n","----------------------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]}]},{"cell_type":"markdown","metadata":{"id":"O5yJIQaQfyXA"},"source":["**Parameters Calculation**\n","\n","| Layer         | Input Weights | Output Weights | No. of bias | Calculation |\n","| -----------   | :---------:   |  :---------:   | :---------: | :---------: |\n","| Linear-1      |    2          |    5           |      5      | 2*5+5 = 15  | \n","| Linear-2      |    5          |    3           |      3      | 5*3+3 = 18  | \n","| Linear-3      |    3          |    2           |      2      | 3*2+2 = 8   | \n","| Linear-4      |    2          |    1           |      1      | 2*1+1 = 3   | "]},{"cell_type":"code","metadata":{"id":"yeotEq19x6XF","executionInfo":{"status":"ok","timestamp":1632537413628,"user_tz":-330,"elapsed":23,"user":{"displayName":"Raja Rajendran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17503276241617911432"}}},"source":["def weights_init(model):\n","    for m in model.modules():\n","        if isinstance(m, nn.Linear):\n","            # initialize the weight tensor, here we use a normal distribution\n","            m.weight.data.normal_(0, 1)\n","\n","weights_init(model)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"WrD_sNzLx78e","executionInfo":{"status":"ok","timestamp":1632537413631,"user_tz":-330,"elapsed":25,"user":{"displayName":"Raja Rajendran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17503276241617911432"}}},"source":["# loss function that measures the mean absolute error (MAE) \n","loss_func = nn.L1Loss()"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"-zvbrMd2x_lA","executionInfo":{"status":"ok","timestamp":1632537413633,"user_tz":-330,"elapsed":26,"user":{"displayName":"Raja Rajendran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17503276241617911432"}}},"source":["optimizer = optim.SGD(model.parameters(), lr=0.02, momentum=0.9)\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q7tWa3D7yA5X","executionInfo":{"status":"ok","timestamp":1632537417962,"user_tz":-330,"elapsed":4354,"user":{"displayName":"Raja Rajendran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17503276241617911432"}},"outputId":"918ba067-32e3-4c05-8e59-6b9a1496fe4d"},"source":["epochs = 2001\n","steps = X.size(0)\n","for i in range(epochs):\n","    for j in range(steps):\n","        # get a random index into X and Y array above\n","        data_point = np.random.randint(X.size(0))\n","        # choose one of the 4 inputs from X based on a  random index\n","        x_var = Variable(X[data_point], requires_grad=False)\n","        # choose the corresponding expected output from Y, for the chosen element in X above\n","        y_var = Variable(Y[data_point], requires_grad=False)\n","        \n","        # zero the gradients for this batch\n","        optimizer.zero_grad()\n","        # use the model to predict the output y_hat, for the input x_var\n","        y_hat = model(x_var)\n","        # compute the loss based on the predicted output y_hat and the expected output y_var\n","        loss = loss_func.forward(y_hat, y_var)\n","        # propogate the loss backward using backward propogation\n","        loss.backward()\n","        # adjust the weights of the model.\n","        optimizer.step()\n","        \n","    if i % 50 == 0:\n","        print( \"Epoch: {0}, Loss: {1}, \".format(i+1, loss.data.numpy()))\n","print( \"Epoch: {0}, Loss: {1}, \".format(i+1, loss.data.numpy()))"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: 1, Loss: 0.6779789924621582, \n","Epoch: 51, Loss: 0.010583728551864624, \n","Epoch: 101, Loss: 0.19995900988578796, \n","Epoch: 151, Loss: 0.08104749768972397, \n","Epoch: 201, Loss: 0.14292266964912415, \n","Epoch: 251, Loss: 0.18490469455718994, \n","Epoch: 301, Loss: 0.270932137966156, \n","Epoch: 351, Loss: 0.0751802921295166, \n","Epoch: 401, Loss: 0.0337519645690918, \n","Epoch: 451, Loss: 0.09669481217861176, \n","Epoch: 501, Loss: 0.20624762773513794, \n","Epoch: 551, Loss: 0.3402632474899292, \n","Epoch: 601, Loss: 0.035258397459983826, \n","Epoch: 651, Loss: 0.07871723175048828, \n","Epoch: 701, Loss: 0.4028509259223938, \n","Epoch: 751, Loss: 0.16474878787994385, \n","Epoch: 801, Loss: 0.08460238575935364, \n","Epoch: 851, Loss: 0.0636419951915741, \n","Epoch: 901, Loss: 0.5936365127563477, \n","Epoch: 951, Loss: 0.04637141525745392, \n","Epoch: 1001, Loss: 0.42788541316986084, \n","Epoch: 1051, Loss: 0.15658414363861084, \n","Epoch: 1101, Loss: 0.007446587085723877, \n","Epoch: 1151, Loss: 0.0569911003112793, \n","Epoch: 1201, Loss: 0.013810373842716217, \n","Epoch: 1251, Loss: 0.07934129238128662, \n","Epoch: 1301, Loss: 0.249519944190979, \n","Epoch: 1351, Loss: 0.36570680141448975, \n","Epoch: 1401, Loss: 0.1507275253534317, \n","Epoch: 1451, Loss: 0.02749747782945633, \n","Epoch: 1501, Loss: 0.18256716430187225, \n","Epoch: 1551, Loss: 0.09129661321640015, \n","Epoch: 1601, Loss: 0.17695105075836182, \n","Epoch: 1651, Loss: 0.016879677772521973, \n","Epoch: 1701, Loss: 0.0008771419525146484, \n","Epoch: 1751, Loss: 0.2331189215183258, \n","Epoch: 1801, Loss: 0.048165082931518555, \n","Epoch: 1851, Loss: 0.21284130215644836, \n","Epoch: 1901, Loss: 0.20873093605041504, \n","Epoch: 1951, Loss: 0.15951162576675415, \n","Epoch: 2001, Loss: 0.08841854333877563, \n","Epoch: 2001, Loss: 0.08841854333877563, \n"]}]},{"cell_type":"markdown","metadata":{"id":"XG_HJ-UQomMo"},"source":["Testing the output"]},{"cell_type":"code","metadata":{"id":"ckG35Yc5n_Ce","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632537417964,"user_tz":-330,"elapsed":35,"user":{"displayName":"Raja Rajendran","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17503276241617911432"}},"outputId":"3bcf80c8-ed45-4c0a-cbd5-ccc050aff233"},"source":["pred = model(X)\n","pred"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n","  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[-0.0076],\n","        [ 0.9658],\n","        [ 0.9775],\n","        [-0.0346]], grad_fn=<AddmmBackward>)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"j_LZrEq8n0rz"},"source":["**References:** http://www.sharetechnote.com/html/Python_PyTorch_nn_Linear_01.html"]}]}